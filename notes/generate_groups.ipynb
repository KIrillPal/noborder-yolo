{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/alpha/projects/wastie/code/kondrashov/delta/notes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/alpha/projects/wastie/code/kondrashov/delta/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /alpha/projects/wastie/code/kondrashov/delta/notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils')\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.interpolate.markup_utils import Mask, load_markup, vis_markup, eternal_dataset_info, is_border_object\n",
    "from utils.interpolate.refine_markup_by_yolo import mask_iou, mask_ioa, poly_mask_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка датасета и модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = '../config.json'\n",
    "SPLIT = 'test'\n",
    "IOU_THRESHOLD = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготавливаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary directory for predictions\n",
    "pred_labels_dir = Path('runs/segment/predict/labels')\n",
    "pred_images_dir = Path('runs/segment/predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.integrate.integrate import shift_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict(obj):\n",
    "    obj = obj.copy()\n",
    "    obj['points'] = np.clip(obj['points'], 0, config['imgsz'])\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from statistics import mode\n",
    "\n",
    "def get_groups(markups, speed, imgsz):\n",
    "    groups = [\n",
    "        [-1] * len(m) for m in markups\n",
    "    ]\n",
    "    group_id = 0\n",
    "    for i, markup in enumerate(tqdm(markups)):\n",
    "        for j, obj in enumerate(markup):\n",
    "            if groups[i][j] != -1:\n",
    "                continue\n",
    "            obj = restrict(obj)\n",
    "            matched_groups = []\n",
    "            # Find if group already exists\n",
    "            idx = i-1\n",
    "            shift = 0\n",
    "            while idx >= 0 and shift < 0.5 * imgsz:\n",
    "                shift += speed[idx + 1]\n",
    "                for k, other_obj in enumerate(markups[idx]):\n",
    "                    obj2 = restrict(shift_mask(other_obj, -shift))\n",
    "                    if mask_ioa(obj, obj2) > IOU_THRESHOLD:\n",
    "                        matched_groups.append(groups[idx][k])\n",
    "                idx -= 1\n",
    "            \n",
    "            if len(matched_groups) > 2:\n",
    "                groups[i][j] = mode(matched_groups)\n",
    "            else:\n",
    "                groups[i][j] = group_id\n",
    "                group_id += 1\n",
    "\n",
    "            # Find next elements from this group\n",
    "            idx = i+1\n",
    "            shift = 0\n",
    "            while idx < len(markups) and shift < 1.2 * imgsz:\n",
    "                shift += speed[idx]\n",
    "                for k, other_obj in enumerate(markups[idx]):\n",
    "                    if groups[idx][k] != -1:\n",
    "                        continue\n",
    "                    if mask_ioa(obj, restrict(shift_mask(other_obj, shift))) > IOU_THRESHOLD:\n",
    "                        groups[idx][k] = groups[i][j]\n",
    "                idx += 1\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD_CLS_TO_NEW_INDICES = {'0': '0', '1': '0', '2': '1'}\n",
    "def cls_transform(markup):\n",
    "    result = []\n",
    "    for m in markup.copy():\n",
    "        m['cls'] = OLD_CLS_TO_NEW_INDICES[m['cls']]\n",
    "        result.append(m)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def get_matches(markups, other):\n",
    "    is_matched = [\n",
    "        [False] * len(m) for m in markups\n",
    "    ]\n",
    "    is_mask_matched = [\n",
    "        [False] * len(m) for m in markups\n",
    "    ]\n",
    "    is_ioa_matched = [\n",
    "        [False] * len(m) for m in markups\n",
    "    ]\n",
    "    is_mask_ioa_matched = [\n",
    "        [False] * len(m) for m in markups\n",
    "    ]\n",
    "    possible_cls = [\n",
    "        [set()] * len(m) for m in markups\n",
    "    ]\n",
    "    for i, markup in enumerate(tqdm(markups)):\n",
    "        for j, obj in enumerate(markup):\n",
    "            obj = restrict(obj)\n",
    "            for other_obj in other[i]:\n",
    "                other_obj = restrict(other_obj)\n",
    "                # Match mask\n",
    "                if mask_iou(obj, other_obj) > IOU_THRESHOLD:\n",
    "                    is_mask_matched[i][j] = True\n",
    "                    # Match class\n",
    "                    if obj['cls'] == other_obj['cls']:\n",
    "                        is_matched[i][j] = True\n",
    "                    else:\n",
    "                        possible_cls[i][j].add(other_obj['cls'])\n",
    "                # if mask_ioa(obj, other_obj) > IOU_THRESHOLD:\n",
    "                #     is_mask_ioa_matched[i][j] = True\n",
    "                #     # Match class\n",
    "                #     if obj['cls'] == other_obj['cls']:\n",
    "                #         is_ioa_matched[i][j] = True\n",
    "                    \n",
    "    return is_matched, is_mask_matched, is_ioa_matched, is_mask_ioa_matched, possible_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_to_groups(group_idx, matching_info, markup, img_paths):\n",
    "    is_matched, is_mask_matched, is_ioa_matched, is_mask_ioa_matched, possible_cls = matching_info\n",
    "    groups = [[] for i in range(max(y for x in group_idx for y in x) + 1)]\n",
    "    for i, group in enumerate(group_idx):\n",
    "        for j, g in enumerate(group):\n",
    "            img_path = img_paths[i]\n",
    "            groups[g].append({\n",
    "                \"img\": img_path, \n",
    "                \"obj\": markup[i][j], \n",
    "                \"is_border\": is_border_object(Mask(markup[i][j]), (config['imgsz'], config['imgsz'])), \n",
    "                \"is_matched\": is_matched[i][j],\n",
    "                \"is_mask_matched\": is_mask_matched[i][j],\n",
    "                \"is_ioa_matched\": is_ioa_matched[i][j],\n",
    "                \"is_mask_ioa_matched\": is_mask_ioa_matched[i][j],\n",
    "                \"possible_cls\": possible_cls[i][j],\n",
    "            })\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предсказание с лучшим по F1 confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_VERSION = 'noborder_aug'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def find_best_conf(model, config):\n",
    "    # Run validation to get best confidence threshold\n",
    "    val_results = model.val(data=config['data'], split=SPLIT, device='cuda:1')\n",
    "\n",
    "    best_f1_idx = np.argmax(val_results.seg.curves_results[1][1].mean(axis=0))\n",
    "    best_f1 = val_results.seg.curves_results[1][1][..., best_f1_idx].mean()\n",
    "    best_conf = val_results.seg.curves_results[1][0][best_f1_idx]\n",
    "    print(f\"Best F1: {best_f1:.4f} at confidence {best_conf:.4f}\")\n",
    "    return best_conf\n",
    "\n",
    "\n",
    "def get_gt_and_predicted_groups(model, config, dataset_path, conf):\n",
    "\n",
    "    # Load labels\n",
    "    dataset_path = Path(dataset_path)\n",
    "    dataset_info = eternal_dataset_info(dataset_path)\n",
    "    gt_labels_dir = Path(dataset_path) / 'gt_interp'\n",
    "    \n",
    "    shutil.rmtree('runs/segment', ignore_errors=True)\n",
    "    # Run YOLO validation to get the best confidence score\n",
    "\n",
    "    # Run prediction with best confidence\n",
    "    for pred in model.predict(\n",
    "        source=str(dataset_path / 'imgs'),\n",
    "        conf=conf,\n",
    "        save_txt=True,\n",
    "        device='cuda:1',\n",
    "        save=True,\n",
    "        stream=True,\n",
    "        save_conf=True,\n",
    "    ):\n",
    "        pass\n",
    "    \n",
    "    gt = []\n",
    "    pred = []\n",
    "    speed = []\n",
    "    gt_paths = sorted(list(gt_labels_dir.glob(\"*.txt\")))\n",
    "    for gt_path in gt_paths:\n",
    "        pred_path = pred_labels_dir / gt_path.name\n",
    "        if not pred_path.exists():\n",
    "            pred_path.touch()\n",
    "        gt.append(cls_transform(load_markup(gt_path, config['imgsz'])))\n",
    "        pred.append(load_markup(pred_path, config['imgsz']))\n",
    "        speed.append(dataset_info['speed'][str(dataset_path / 'imgs' / (gt_path.stem + '.jpg'))])\n",
    "\n",
    "    gt_img_paths = [p.parent.parent / 'imgs' / f'{p.stem}.jpg' for p in gt_paths]\n",
    "    pred_img_paths = [pred_images_dir / f'{p.stem}.jpg' for p in gt_paths]\n",
    "\n",
    "    gt_group_idx = get_groups(gt, speed, config['imgsz'])\n",
    "    gt_matching_info = get_matches(gt, pred)\n",
    "    gt_groups = idx_to_groups(gt_group_idx, gt_matching_info, gt, gt_img_paths)\n",
    "    \n",
    "    pred_group_idx = get_groups(pred, speed, config['imgsz'])\n",
    "    pred_matching_info = get_matches(pred, gt)\n",
    "    pred_groups = idx_to_groups(pred_group_idx, pred_matching_info, pred, pred_img_paths)\n",
    "    \n",
    "    return gt_groups, pred_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_groups_per_dataset = []\n",
    "# pred_groups_per_dataset = []\n",
    "\n",
    "# from ultralytics import YOLO\n",
    "# model = YOLO(config['models'][MODEL_VERSION])\n",
    "# import torch\n",
    "\n",
    "# conf = find_best_conf(model, config)\n",
    "\n",
    "# for dataset_path in config['interpolated']['datasets']:\n",
    "#     gt_groups, pred_groups = get_gt_and_predicted_groups(model, config, dataset_path, conf)\n",
    "#     gt_groups_per_dataset.append(gt_groups)\n",
    "#     pred_groups_per_dataset.append(pred_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOSEN_DATASETS = config['interpolated']['datasets']['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.48 🚀 Python-3.10.12 torch-2.6.0+cu124 CUDA:1 (NVIDIA A100 80GB PCIe, 81154MiB)\n",
      "YOLOv8m-seg summary (fused): 263 layers, 24,586,614 parameters, 0 gradients, 98.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /alpha/projects/wastie/datasets/25_12_2_classes_fpfn_update_v2/test/labels.cache... 731 images, 150 backgrounds, 0 corrupt: 100%|██████████| 731/731 [00:00<?, ?it/s]\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 46/46 [00:10<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        731       4144      0.925      0.886      0.952      0.843      0.926      0.887      0.951      0.788\n",
      "                   bot        540       3093      0.914      0.866      0.946      0.836      0.916      0.868      0.945      0.784\n",
      "                  alum        428       1051      0.936      0.906      0.957      0.849      0.936      0.906      0.957      0.792\n",
      "Speed: 0.7ms preprocess, 4.3ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/val\u001b[0m\n",
      "Best F1: 0.9067 at confidence 0.4555\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 16\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset_path \u001b[38;5;129;01min\u001b[39;00m CHOSEN_DATASETS:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# gt_groups, pred_groups = get_gt_and_predicted_groups(model, config, dataset_path, conf)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# gt_groups_per_dataset.append(gt_groups)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# pred_groups_per_dataset.append(pred_groups)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m img_path \u001b[38;5;129;01min\u001b[39;00m (Path(dataset_path) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimgs\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39miterdir():\n\u001b[0;32m---> 16\u001b[0m         \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/alpha/projects/wastie/code/kondrashov/delta/data/common_test/imgs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/shutil.py:417\u001b[0m, in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[1;32m    416\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[0;32m--> 417\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m copymode(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[0;32m/usr/lib/python3.10/shutil.py:258\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;66;03m# macOS\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _HAS_FCOPYFILE:\n\u001b[1;32m    259\u001b[0m             \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    260\u001b[0m                 _fastcopy_fcopyfile(fsrc, fdst, posix\u001b[38;5;241m.\u001b[39m_COPYFILE_DATA)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gt_groups_per_dataset = []\n",
    "pred_groups_per_dataset = []\n",
    "\n",
    "from ultralytics import YOLO\n",
    "model = YOLO('/alpha/projects/wastie/code/kondrashov/tmp/dense_models/24_12.pt')\n",
    "import torch\n",
    "\n",
    "conf = find_best_conf(model, config)\n",
    "#conf = 0.6\n",
    "\n",
    "for dataset_path in CHOSEN_DATASETS:\n",
    "    # gt_groups, pred_groups = get_gt_and_predicted_groups(model, config, dataset_path, conf)\n",
    "    # gt_groups_per_dataset.append(gt_groups)\n",
    "    # pred_groups_per_dataset.append(pred_groups)\n",
    "    for img_path in (Path(dataset_path) / 'imgs').iterdir():\n",
    "        copy(img_path, '/alpha/projects/wastie/code/kondrashov/delta/data/trainval/imgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update border objects and calculate area\n",
    "for g in gt_groups:\n",
    "    for instance in g:\n",
    "        instance['is_border'] = is_border_object(Mask(instance['obj']), (config['imgsz'], config['imgsz']))\n",
    "        instance['area'] = poly_mask_area(instance['obj'])\n",
    "for g in pred_groups:\n",
    "    for instance in g:\n",
    "        instance['is_border'] = is_border_object(Mask(instance['obj']), (config['imgsz'], config['imgsz']))\n",
    "        instance['area'] = poly_mask_area(instance['obj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate area share based on the group's max area\n",
    "for groupset in [gt_groups, pred_groups]:\n",
    "    for g in groupset:\n",
    "        max_area = max([instance['area'] for instance in g])\n",
    "        for instance in g:\n",
    "            instance['area_share'] = instance['area'] / max_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('gt_24_12_dense_c06.pkl', 'wb') as f:\n",
    "    pickle.dump(gt_groups, f)\n",
    "with open('pred_24_12_dense_c06.pkl', 'wb') as f:\n",
    "    pickle.dump(pred_groups, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('gt_groups_test_extended.pkl', 'wb') as f:\n",
    "#     pickle.dump(gt_groups, f)\n",
    "# with open('pred_groups_test_extended.pkl', 'wb') as f:\n",
    "#     pickle.dump(pred_groups, f)\n",
    "# with open('gt_groups_per_dataset_trainval.pkl', 'wb') as f:\n",
    "#     pickle.dump(gt_groups_per_dataset, f)\n",
    "# with open('pred_groups_per_dataset_trainval.pkl', 'wb') as f:\n",
    "#     pickle.dump(pred_groups_per_dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация общего датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'gt_groups_per_dataset_trainval.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# with open('gt_groups.pkl', 'rb') as f:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     gt_groups = pickle.load(f)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# with open('pred_groups.pkl', 'rb') as f:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#     pred_groups = pickle.load(f)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgt_groups_per_dataset_trainval.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      7\u001b[0m     gt_groups_per_dataset \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_groups_per_dataset_trainval.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/alpha/projects/wastie/code/kondrashov/delta/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gt_groups_per_dataset_trainval.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# with open('gt_groups.pkl', 'rb') as f:\n",
    "#     gt_groups = pickle.load(f)\n",
    "# with open('pred_groups.pkl', 'rb') as f:\n",
    "#     pred_groups = pickle.load(f)\n",
    "with open('gt_groups_per_dataset_trainval.pkl', 'rb') as f:\n",
    "    gt_groups_per_dataset = pickle.load(f)\n",
    "with open('pred_groups_per_dataset_trainval.pkl', 'rb') as f:\n",
    "    pred_groups_per_dataset = pickle.load(f)\n",
    "\n",
    "gt_groups = []\n",
    "pred_groups = []\n",
    "for gt_group in gt_groups_per_dataset:\n",
    "    gt_groups += gt_group\n",
    "for pred_group in pred_groups_per_dataset:\n",
    "    pred_groups += pred_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_groups = []\n",
    "pred_groups = []\n",
    "for gt_group in gt_groups_per_dataset:\n",
    "    gt_groups += gt_group\n",
    "for pred_group in pred_groups_per_dataset:\n",
    "    pred_groups += pred_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12333"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('gt_test_dense.pkl', 'rb') as f:\n",
    "    gt_groups = pickle.load(f)\n",
    "with open('pred_test_dense.pkl', 'rb') as f:\n",
    "    pred_groups = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Отфильтурем объекты по тем, что встречались в неинтерполированном тестовом датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "interp_test_imgs_path = Path(config['interpolated']['test']).parent / 'test' / 'images'\n",
    "#interpolated_test_names = set(p.name for p in interp_test_imgs_path.iterdir() if p.name.startswith('tula_sep_0002_2024_07_22_18'))\n",
    "interpolated_test_names = set(p.name for p in interp_test_imgs_path.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_groups = [[m for m in g if m['img'].name in interpolated_test_names] for g in gt_groups]\n",
    "gt_groups = [g for g in gt_groups if len(g) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_groups = [[m for m in g if m['img'].name in interpolated_test_names] for g in pred_groups]\n",
    "pred_groups = [g for g in pred_groups if len(g) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tula_sep_0002_2024_07_16_14 \t 8994\n",
      "tula_sep_0002_2024_07_16_15 \t 8221\n"
     ]
    }
   ],
   "source": [
    "cnt = {}\n",
    "for g in pred_groups:\n",
    "    for m in g:\n",
    "        dir = m['img'].name[:len('tula_sep_0002_2024_07_22_18')]\n",
    "        if dir not in cnt:\n",
    "            cnt[dir] = 0\n",
    "        cnt[dir] += 1\n",
    "for k, v in cnt.items():\n",
    "    print(k, '\\t', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tula_sep_0002_2024_07_16_14 \t 10935\n",
      "tula_sep_0002_2024_07_16_15 \t 9748\n"
     ]
    }
   ],
   "source": [
    "cnt = {}\n",
    "for g in gt_groups:\n",
    "    for m in g:\n",
    "        dir = m['img'].name[:len('tula_sep_0002_2024_07_22_18')]\n",
    "        if dir not in cnt:\n",
    "            cnt[dir] = 0\n",
    "        cnt[dir] += 1\n",
    "for k, v in cnt.items():\n",
    "    print(k, '\\t', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Добавим дополнительные свойства"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update border objects and calculate area\n",
    "for g in gt_groups:\n",
    "    for instance in g:\n",
    "        instance['is_border'] = is_border_object(Mask(instance['obj']), (config['imgsz'], config['imgsz']))\n",
    "        instance['area'] = poly_mask_area(instance['obj'])\n",
    "for g in pred_groups:\n",
    "    for instance in g:\n",
    "        instance['is_border'] = is_border_object(Mask(instance['obj']), (config['imgsz'], config['imgsz']))\n",
    "        instance['area'] = poly_mask_area(instance['obj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate area share based on the group's max area\n",
    "for groupset in [gt_groups, pred_groups]:\n",
    "    for g in groupset:\n",
    "        max_area = max([instance['area'] for instance in g])\n",
    "        for instance in g:\n",
    "            instance['area_share'] = instance['area'] / max_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Delta",
   "language": "python",
   "name": "delta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
