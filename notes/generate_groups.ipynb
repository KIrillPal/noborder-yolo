{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils')\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.interpolate.markup_utils import Mask, load_markup, vis_markup, eternal_dataset_info, is_border_object\n",
    "from utils.interpolate.refine_markup_by_yolo import mask_iou, mask_ioa, poly_mask_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка датасета и модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = '../config.json'\n",
    "SPLIT = 'test'\n",
    "IOU_THRESHOLD = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготавливаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary directory for predictions\n",
    "pred_labels_dir = Path('runs/segment/predict/labels')\n",
    "pred_images_dir = Path('runs/segment/predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.integrate.integrate import shift_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict(obj):\n",
    "    obj = obj.copy()\n",
    "    obj['points'] = np.clip(obj['points'], 0, config['imgsz'])\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from statistics import mode\n",
    "\n",
    "def get_groups(markups, speed, imgsz):\n",
    "    groups = [\n",
    "        [-1] * len(m) for m in markups\n",
    "    ]\n",
    "    group_id = 0\n",
    "    for i, markup in enumerate(tqdm(markups)):\n",
    "        for j, obj in enumerate(markup):\n",
    "            if groups[i][j] != -1:\n",
    "                continue\n",
    "            obj = restrict(obj)\n",
    "            matched_groups = []\n",
    "            # Find if group already exists\n",
    "            idx = i-1\n",
    "            shift = 0\n",
    "            while idx >= 0 and shift < 0.5 * imgsz:\n",
    "                shift += speed[idx + 1]\n",
    "                for k, other_obj in enumerate(markups[idx]):\n",
    "                    obj2 = restrict(shift_mask(other_obj, -shift))\n",
    "                    if mask_ioa(obj, obj2) > IOU_THRESHOLD:\n",
    "                        matched_groups.append(groups[idx][k])\n",
    "                idx -= 1\n",
    "            \n",
    "            if len(matched_groups) > 2:\n",
    "                groups[i][j] = mode(matched_groups)\n",
    "            else:\n",
    "                groups[i][j] = group_id\n",
    "                group_id += 1\n",
    "\n",
    "            # Find next elements from this group\n",
    "            idx = i+1\n",
    "            shift = 0\n",
    "            while idx < len(markups) and shift < 1.2 * imgsz:\n",
    "                shift += speed[idx]\n",
    "                for k, other_obj in enumerate(markups[idx]):\n",
    "                    if groups[idx][k] != -1:\n",
    "                        continue\n",
    "                    if mask_ioa(obj, restrict(shift_mask(other_obj, shift))) > IOU_THRESHOLD:\n",
    "                        groups[idx][k] = groups[i][j]\n",
    "                idx += 1\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD_CLS_TO_NEW_INDICES = {'0': '0', '1': '0', '2': '1'}\n",
    "def cls_transform(markup):\n",
    "    result = []\n",
    "    for m in markup.copy():\n",
    "        m['cls'] = OLD_CLS_TO_NEW_INDICES[m['cls']]\n",
    "        result.append(m)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def get_matches(markups, other):\n",
    "    is_matched = [\n",
    "        [False] * len(m) for m in markups\n",
    "    ]\n",
    "    is_mask_matched = [\n",
    "        [False] * len(m) for m in markups\n",
    "    ]\n",
    "    is_ioa_matched = [\n",
    "        [False] * len(m) for m in markups\n",
    "    ]\n",
    "    is_mask_ioa_matched = [\n",
    "        [False] * len(m) for m in markups\n",
    "    ]\n",
    "    for i, markup in enumerate(tqdm(markups)):\n",
    "        for j, obj in enumerate(markup):\n",
    "            obj = restrict(obj)\n",
    "            for other_obj in other[i]:\n",
    "                other_obj = restrict(other_obj)\n",
    "                # Match mask\n",
    "                if mask_iou(obj, other_obj) > IOU_THRESHOLD:\n",
    "                    is_mask_matched[i][j] = True\n",
    "                    # Match class\n",
    "                    if obj['cls'] == other_obj['cls']:\n",
    "                        is_matched[i][j] = True\n",
    "                if mask_ioa(obj, other_obj) > IOU_THRESHOLD:\n",
    "                    is_mask_ioa_matched[i][j] = True\n",
    "                    # Match class\n",
    "                    if obj['cls'] == other_obj['cls']:\n",
    "                        is_ioa_matched[i][j] = True\n",
    "                    \n",
    "    return is_matched, is_mask_matched, is_ioa_matched, is_mask_ioa_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_to_groups(group_idx, matching_info, markup, img_paths):\n",
    "    is_matched, is_mask_matched, is_ioa_matched, is_mask_ioa_matched = matching_info\n",
    "    groups = [[] for i in range(max(y for x in group_idx for y in x) + 1)]\n",
    "    for i, group in enumerate(group_idx):\n",
    "        for j, g in enumerate(group):\n",
    "            img_path = img_paths[i]\n",
    "            groups[g].append({\n",
    "                \"img\": img_path, \n",
    "                \"obj\": markup[i][j], \n",
    "                \"is_border\": is_border_object(Mask(markup[i][j]), (config['imgsz'], config['imgsz'])), \n",
    "                \"is_matched\": is_matched[i][j],\n",
    "                \"is_mask_matched\": is_mask_matched[i][j],\n",
    "                \"is_ioa_matched\": is_ioa_matched[i][j],\n",
    "                \"is_mask_ioa_matched\": is_mask_ioa_matched[i][j]\n",
    "            })\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предсказание с лучшим по F1 confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_VERSION = 'default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "def find_best_conf(model, config):\n",
    "    # Run validation to get best confidence threshold\n",
    "    val_results = model.val(data=config['data'], split=SPLIT, device='cuda:1')\n",
    "\n",
    "    best_f1_idx = np.argmax(val_results.seg.curves_results[1][1].mean(axis=0))\n",
    "    best_f1 = val_results.seg.curves_results[1][1][..., best_f1_idx].mean()\n",
    "    best_conf = val_results.seg.curves_results[1][0][best_f1_idx]\n",
    "    print(f\"Best F1: {best_f1:.4f} at confidence {best_conf:.4f}\")\n",
    "    return best_conf\n",
    "\n",
    "\n",
    "def get_gt_and_predicted_groups(model, config, dataset_path, conf):\n",
    "\n",
    "    # Load labels\n",
    "    dataset_path = Path(dataset_path)\n",
    "    dataset_info = eternal_dataset_info(dataset_path)\n",
    "    gt_labels_dir = Path(dataset_path) / 'gt_interp'\n",
    "    \n",
    "    shutil.rmtree('runs/segment', ignore_errors=True)\n",
    "    # Run YOLO validation to get the best confidence score\n",
    "\n",
    "    # Run prediction with best confidence\n",
    "    for pred in model.predict(\n",
    "        source=str(dataset_path / 'imgs'),\n",
    "        conf=conf,\n",
    "        save_txt=True,\n",
    "        device='cuda:1',\n",
    "        save=True,\n",
    "        stream=True\n",
    "    ):\n",
    "        pass\n",
    "    \n",
    "    gt = []\n",
    "    pred = []\n",
    "    speed = []\n",
    "    gt_paths = sorted(list(gt_labels_dir.glob(\"*.txt\")))\n",
    "    for gt_path in gt_paths:\n",
    "        pred_path = pred_labels_dir / gt_path.name\n",
    "        if not pred_path.exists():\n",
    "            pred_path.touch()\n",
    "        gt.append(cls_transform(load_markup(gt_path, config['imgsz'])))\n",
    "        pred.append(load_markup(pred_path, config['imgsz']))\n",
    "        speed.append(dataset_info['speed'][str(dataset_path / 'imgs' / (gt_path.stem + '.jpg'))])\n",
    "\n",
    "    gt_img_paths = [p.parent.parent / 'imgs' / f'{p.stem}.jpg' for p in gt_paths]\n",
    "    pred_img_paths = [pred_images_dir / f'{p.stem}.jpg' for p in gt_paths]\n",
    "\n",
    "    gt_group_idx = get_groups(gt, speed, config['imgsz'])\n",
    "    gt_matching_info = get_matches(gt, pred)\n",
    "    gt_groups = idx_to_groups(gt_group_idx, gt_matching_info, gt, gt_img_paths)\n",
    "    \n",
    "    pred_group_idx = get_groups(pred, speed, config['imgsz'])\n",
    "    pred_matching_info = get_matches(pred, gt)\n",
    "    pred_groups = idx_to_groups(pred_group_idx, pred_matching_info, pred, pred_img_paths)\n",
    "    \n",
    "    return gt_groups, pred_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_groups_per_dataset = []\n",
    "# pred_groups_per_dataset = []\n",
    "\n",
    "# from ultralytics import YOLO\n",
    "# model = YOLO(config['models'][MODEL_VERSION])\n",
    "# import torch\n",
    "\n",
    "# conf = find_best_conf(model, config)\n",
    "\n",
    "# for dataset_path in config['interpolated']['datasets']:\n",
    "#     gt_groups, pred_groups = get_gt_and_predicted_groups(model, config, dataset_path, conf)\n",
    "#     gt_groups_per_dataset.append(gt_groups)\n",
    "#     pred_groups_per_dataset.append(pred_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOSEN_DATASETS = ['/alpha/projects/wastie/code/kondrashov/delta/data/sparse_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.48 🚀 Python-3.10.12 torch-2.6.0+cu124 CUDA:1 (NVIDIA A100 80GB PCIe, 81154MiB)\n",
      "YOLOv8m-seg summary (fused): 263 layers, 24,586,614 parameters, 0 gradients, 98.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /alpha/projects/wastie/datasets/25_12_2_classes_fpfn_update_v2/test/labels.cache... 731 images, 150 backgrounds, 0 corrupt: 100%|██████████| 731/731 [00:00<?, ?it/s]\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 46/46 [00:11<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        731       4144       0.91      0.889      0.953      0.848       0.91       0.89      0.952      0.799\n",
      "                   bot        540       3093      0.899      0.882      0.951      0.845      0.901      0.884       0.95      0.794\n",
      "                  alum        428       1051       0.92      0.896      0.956      0.851      0.919      0.895      0.953      0.805\n",
      "Speed: 1.0ms preprocess, 6.6ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/val2\u001b[0m\n",
      "Best F1: 0.9018 at confidence 0.3854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3814/3814 [02:43<00:00, 23.28it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3814/3814 [01:28<00:00, 43.18it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3814/3814 [02:19<00:00, 27.25it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3814/3814 [01:28<00:00, 43.27it/s]\n"
     ]
    }
   ],
   "source": [
    "gt_groups_per_dataset = []\n",
    "pred_groups_per_dataset = []\n",
    "\n",
    "from ultralytics import YOLO\n",
    "model = YOLO(config['models'][MODEL_VERSION])\n",
    "import torch\n",
    "\n",
    "conf = find_best_conf(model, config)\n",
    "\n",
    "for dataset_path in CHOSEN_DATASETS:\n",
    "    gt_groups, pred_groups = get_gt_and_predicted_groups(model, config, dataset_path, conf)\n",
    "    gt_groups_per_dataset.append(gt_groups)\n",
    "    pred_groups_per_dataset.append(pred_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update border objects and calculate area\n",
    "for g in gt_groups:\n",
    "    for instance in g:\n",
    "        instance['is_border'] = is_border_object(Mask(instance['obj']), (config['imgsz'], config['imgsz']))\n",
    "        instance['area'] = poly_mask_area(instance['obj'])\n",
    "for g in pred_groups:\n",
    "    for instance in g:\n",
    "        instance['is_border'] = is_border_object(Mask(instance['obj']), (config['imgsz'], config['imgsz']))\n",
    "        instance['area'] = poly_mask_area(instance['obj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate area share based on the group's max area\n",
    "for groupset in [gt_groups, pred_groups]:\n",
    "    for g in groupset:\n",
    "        max_area = max([instance['area'] for instance in g])\n",
    "        for instance in g:\n",
    "            instance['area_share'] = instance['area'] / max_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('gt_test_sparse.pkl', 'wb') as f:\n",
    "    pickle.dump(gt_groups, f)\n",
    "with open('pred_test_sparse.pkl', 'wb') as f:\n",
    "    pickle.dump(pred_groups, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('gt_groups_test_extended.pkl', 'wb') as f:\n",
    "#     pickle.dump(gt_groups, f)\n",
    "# with open('pred_groups_test_extended.pkl', 'wb') as f:\n",
    "#     pickle.dump(pred_groups, f)\n",
    "# with open('gt_groups_per_dataset_test_extended.pkl', 'wb') as f:\n",
    "#     pickle.dump(gt_groups_per_dataset, f)\n",
    "# with open('pred_groups_per_dataset_test_extended.pkl', 'wb') as f:\n",
    "#     pickle.dump(pred_groups_per_dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация общего датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# with open('gt_groups.pkl', 'rb') as f:\n",
    "#     gt_groups = pickle.load(f)\n",
    "# with open('pred_groups.pkl', 'rb') as f:\n",
    "#     pred_groups = pickle.load(f)\n",
    "with open('gt_groups_per_dataset_test_extended.pkl', 'rb') as f:\n",
    "    gt_groups_per_dataset = pickle.load(f)\n",
    "with open('pred_groups_per_dataset_test_extended.pkl', 'rb') as f:\n",
    "    pred_groups_per_dataset = pickle.load(f)\n",
    "\n",
    "gt_groups = []\n",
    "pred_groups = []\n",
    "for gt_group in gt_groups_per_dataset:\n",
    "    gt_groups += gt_group\n",
    "for pred_group in pred_groups_per_dataset:\n",
    "    pred_groups += pred_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('gt_test_dense.pkl', 'rb') as f:\n",
    "    gt_groups = pickle.load(f)\n",
    "with open('pred_test_dense.pkl', 'rb') as f:\n",
    "    pred_groups = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Отфильтурем объекты по тем, что встречались в неинтерполированном тестовом датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "interp_test_imgs_path = Path(config['interpolated']['test']).parent / 'test' / 'images'\n",
    "#interpolated_test_names = set(p.name for p in interp_test_imgs_path.iterdir() if p.name.startswith('tula_sep_0002_2024_07_22_18'))\n",
    "interpolated_test_names = set(p.name for p in interp_test_imgs_path.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_groups = [[m for m in g if m['img'].name in interpolated_test_names] for g in gt_groups]\n",
    "gt_groups = [g for g in gt_groups if len(g) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_groups = [[m for m in g if m['img'].name in interpolated_test_names] for g in pred_groups]\n",
    "pred_groups = [g for g in pred_groups if len(g) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tula_sep_0002_2024_07_16_14 \t 8994\n",
      "tula_sep_0002_2024_07_16_15 \t 8221\n"
     ]
    }
   ],
   "source": [
    "cnt = {}\n",
    "for g in pred_groups:\n",
    "    for m in g:\n",
    "        dir = m['img'].name[:len('tula_sep_0002_2024_07_22_18')]\n",
    "        if dir not in cnt:\n",
    "            cnt[dir] = 0\n",
    "        cnt[dir] += 1\n",
    "for k, v in cnt.items():\n",
    "    print(k, '\\t', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tula_sep_0002_2024_07_16_14 \t 10935\n",
      "tula_sep_0002_2024_07_16_15 \t 9748\n"
     ]
    }
   ],
   "source": [
    "cnt = {}\n",
    "for g in gt_groups:\n",
    "    for m in g:\n",
    "        dir = m['img'].name[:len('tula_sep_0002_2024_07_22_18')]\n",
    "        if dir not in cnt:\n",
    "            cnt[dir] = 0\n",
    "        cnt[dir] += 1\n",
    "for k, v in cnt.items():\n",
    "    print(k, '\\t', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Добавим дополнительные свойства"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update border objects and calculate area\n",
    "for g in gt_groups:\n",
    "    for instance in g:\n",
    "        instance['is_border'] = is_border_object(Mask(instance['obj']), (config['imgsz'], config['imgsz']))\n",
    "        instance['area'] = poly_mask_area(instance['obj'])\n",
    "for g in pred_groups:\n",
    "    for instance in g:\n",
    "        instance['is_border'] = is_border_object(Mask(instance['obj']), (config['imgsz'], config['imgsz']))\n",
    "        instance['area'] = poly_mask_area(instance['obj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate area share based on the group's max area\n",
    "for groupset in [gt_groups, pred_groups]:\n",
    "    for g in groupset:\n",
    "        max_area = max([instance['area'] for instance in g])\n",
    "        for instance in g:\n",
    "            instance['area_share'] = instance['area'] / max_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Delta",
   "language": "python",
   "name": "delta"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
